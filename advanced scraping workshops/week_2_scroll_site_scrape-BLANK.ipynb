{"nbformat":4,"nbformat_minor":5,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Copy of week_2_scroll_site_scrape-BLANK.ipynb","provenance":[{"file_id":"1Fq1LP3u9UtK5fW7i6TzJ566MbTD_q2AP","timestamp":1635900327906}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"cb6d7af4"},"source":["## Scraping scrollers\n","\n","Infinite scroll sites are designed for the mobile age. Links are hard to tap with a finger on a small device,  but a simple swipe easily scrolls the page down to reveal more data. That can make scraping an infinite scroll page difficult. We’ll learn to find the actual location of the data buried in the scrolls.\n","\n","Here's a couple of examples of a scrolling sites: \n","\n","- <a href=\"https://www.difc.ae/public-register/\">DIFC Public Register</a>\n","\n","- <a href=\"https://www.quintoandar.com.br/alugar/imovel/sao-paulo-sp-brasil\">Rentals in São Paulo</a>\n","\n","Let's target the data source we'll need to scrape this <a href=\"https://quotes.toscrape.com/scroll\">mockup site</a>.\n","\n","\n","\n","\n","\n"],"id":"cb6d7af4"},{"cell_type":"markdown","metadata":{"id":"6tJdvD9FQWXf"},"source":["### we want ice cream!"],"id":"6tJdvD9FQWXf"},{"cell_type":"code","metadata":{"id":"e739b2ad"},"source":["pip install icecream"],"id":"e739b2ad","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a17111ee"},"source":["## Lets import all the libaries we are likely to need\n","import requests ## to capture content from web pages\n","from bs4 import BeautifulSoup ## to parse our scraped data\n","import pandas as pd ## to easily export our data to dataframes/CSVs\n","from icecream import ic ## easily debug\n","from pprint import pprint as pp ## to prettify our printouts\n","import itertools ## to flatten lists\n","from random import randrange ## to create a range of numbers\n","import time # for timer\n","import json ## to work with JSON data"],"id":"a17111ee","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"11ac7588"},"source":["### Figure out how to scape a single page"],"id":"11ac7588"},{"cell_type":"code","metadata":{"id":"98d1cc6c"},"source":[""],"id":"98d1cc6c","execution_count":null,"outputs":[]}]}