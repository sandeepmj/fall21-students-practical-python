{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fv1F1HyA9zmX"
   },
   "source": [
    "# Capture and organize data in downloaded files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsXo4Upb9zmb"
   },
   "source": [
    "We downloaded these ```.txt``` and ```.pdf``` files in our most recent scrape. We won't scrape them again. \n",
    "\n",
    "We will read the text files using Python and export data to csv. (are you seeing a pattern yet?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyvc6CPd-FUC"
   },
   "source": [
    "# Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: icecream in /usr/local/anaconda3/lib/python3.8/site-packages (2.1.1)\n",
      "Requirement already satisfied: executing>=0.3.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from icecream) (0.8.0)\n",
      "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/anaconda3/lib/python3.8/site-packages (from icecream) (2.0.5)\n",
      "Requirement already satisfied: pygments>=2.2.0 in /usr/local/anaconda3/lib/python3.8/site-packages (from icecream) (2.8.1)\n",
      "Requirement already satisfied: colorama>=0.3.9 in /usr/local/anaconda3/lib/python3.8/site-packages (from icecream) (0.4.4)\n",
      "Requirement already satisfied: six in /usr/local/anaconda3/lib/python3.8/site-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m2ru6dyM9zmb"
   },
   "outputs": [],
   "source": [
    "## in order to export our file to our computer drive, you need this only in Colab:\n",
    "# from google.colab import files\n",
    "import os ## for file/folder management\n",
    "from pathlib import Path ## to provide a path to files/folders\n",
    "## import the glob library for collecting specific files into a list\n",
    "import glob \n",
    "import pandas as pd ## to export csv file\n",
    "from icecream import ic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AB2_Oy8HlCRW"
   },
   "source": [
    "## where am i?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CAuO3kqilCRW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mmanyFiles\u001b[m\u001b[m/\r\n",
      "week-1-working-with-datatypes-BLANKS.ipynb\r\n",
      "week-2-inclass-exercises-BLANKS.ipynb\r\n",
      "week-2-inclass-exercises-DEMO.ipynb\r\n",
      "week-3-A-list comprehensions BLANKS.ipynb\r\n",
      "week-3-A-list comprehensions DEMO.ipynb\r\n",
      "week-3-B-defined-functions-BLANKS.ipynb\r\n",
      "week-3-B-defined-functions-DEMO.ipynb\r\n",
      "week-3-C-Lambdas-BLANK.ipynb\r\n",
      "week-4-scraping-intro-beautifulsoup-BLANKS.ipynb\r\n",
      "week-4-scraping-intro-beautifulsoup-DEMO.ipynb\r\n",
      "week-5-A-single-page-table_BLANKS.ipynb\r\n",
      "week-5-A-single-page-table_DEMO.ipynb\r\n",
      "week-5-B-inclass-non-tabular-scrape_BLANKS.ipynb\r\n",
      "week-5-B-inclass-non-tabular-scrape_DEMO.ipynb\r\n",
      "week-6-multi-page-table-scrape-BLANK.ipynb\r\n",
      "week-6-multi-page-table-scrape-DEMO.ipynb\r\n",
      "week-7-download_docs_BLANK.ipynb\r\n",
      "week-7-download_docs_DEMO.ipynb\r\n",
      "week-7-flattening_lists_BLANK.ipynb\r\n",
      "week-7-flattening_lists_DEMO.ipynb\r\n",
      "\u001b[1m\u001b[36mweek-8-practice-files\u001b[m\u001b[m/\r\n",
      "\u001b[1m\u001b[36mweek-8-sample-folder\u001b[m\u001b[m/\r\n",
      "week-8-sample-folder.zip\r\n",
      "week-8A-file_folder_mngmt_BLANK.ipynb\r\n",
      "week-8A-file_folder_mngmt_DEMO.ipynb\r\n",
      "week-8B-download-and-read_BLANK.ipynb\r\n",
      "week-8C-practice-files.zip\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"manyFiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_01.txt',\n",
       " 'decision_03.txt',\n",
       " 'decision_02.txt',\n",
       " 'decision_06.txt',\n",
       " 'decision_07.txt',\n",
       " 'decision_05.txt',\n",
       " 'decision_04.txt',\n",
       " 'decision_10.txt',\n",
       " 'Sackler-email.png',\n",
       " 'big_revenue.csv',\n",
       " 'spanish.jpg',\n",
       " 'decision_09.txt',\n",
       " 'decision_08.txt',\n",
       " 'form.png',\n",
       " 'EMIRATESNBD_NOT_13_11_2019.pdf']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ezd1IYJQD95X"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['decision_01.txt',\n",
       " 'decision_02.txt',\n",
       " 'decision_03.txt',\n",
       " 'decision_04.txt',\n",
       " 'decision_05.txt',\n",
       " 'decision_06.txt',\n",
       " 'decision_07.txt',\n",
       " 'decision_08.txt',\n",
       " 'decision_09.txt',\n",
       " 'decision_10.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let's capture the files in a list\n",
    "## unlike earlier when when we capture the locations,\n",
    "## these are the actual files with their contents.\n",
    "myfiles = sorted(glob.glob(\"*.txt\"))\n",
    "myfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fvax9kwamuMx"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n",
      "ic| type(textfile): <class '_io.TextIOWrapper'>\n"
     ]
    }
   ],
   "source": [
    "#let's turn each file into readable content\n",
    "for myfile in myfiles:\n",
    "#     ic(myfile)\n",
    "    with open(myfile, \"r\") as textfile:\n",
    "        ic(type(textfile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdcgUwoknrrd"
   },
   "source": [
    "## We can interpret this ```<class '_io.TextIOWrapper'>``` to read the actual contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fqN9xmTuD-Ao"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n",
      "ic| textfile.readline(): 'Year: 2018\n",
      "                          '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source is decision_01.txt\n",
      "source is decision_02.txt\n",
      "source is decision_03.txt\n",
      "source is decision_04.txt\n",
      "source is decision_05.txt\n",
      "source is decision_06.txt\n",
      "source is decision_07.txt\n",
      "source is decision_08.txt\n",
      "source is decision_09.txt\n",
      "source is decision_10.txt\n"
     ]
    }
   ],
   "source": [
    "## let's see what the first line of each file contains\n",
    "\n",
    "for myfile in myfiles:\n",
    "#     ic(myfile)\n",
    "    with open(myfile, \"r\") as textfile:\n",
    "        ic(textfile.readline())\n",
    "        print(f\"source is {myfile}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WmZYM2D4D99U",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The order provides 24-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to not suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The order remains for partial care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                \"The appellant was determined to suffer from Alzheimer's disease.  \n",
      "               \",\n",
      "                '\n",
      "               ',\n",
      "                'This order provides 24-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'This order provides 12-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'This order provides 12-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'This order provides 12-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to not suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The order remains for partial care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The order provides 24-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The order provides 24-hour care.']\n",
      "ic| all_lines: ['Year: 2018\n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The appellant was determined to suffer from Dementia.  \n",
      "               ',\n",
      "                '\n",
      "               ',\n",
      "                'The order provides 24-hour care.']\n"
     ]
    }
   ],
   "source": [
    "## let's see what each entire file contains\n",
    "for myfile in myfiles:\n",
    "#     ic(myfile)\n",
    "    with open(myfile, \"r\") as textfile:\n",
    "        all_lines = textfile.readlines()\n",
    "        ic(all_lines)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "oU_37TIvD-Dl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '24',\n",
       "  'source': 'decision_01.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': False,\n",
       "  'condition': 'A/D not indicated ',\n",
       "  'care_hours': 'not specified',\n",
       "  'source': 'decision_02.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': \"Alzheimer's\",\n",
       "  'care_hours': '24',\n",
       "  'source': 'decision_03.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '12',\n",
       "  'source': 'decision_04.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '12',\n",
       "  'source': 'decision_05.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '12',\n",
       "  'source': 'decision_06.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': False,\n",
       "  'condition': 'A/D not indicated ',\n",
       "  'care_hours': 'not specified',\n",
       "  'source': 'decision_07.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '24',\n",
       "  'source': 'decision_08.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '24',\n",
       "  'source': 'decision_09.txt'},\n",
       " {'year': '2018',\n",
       "  'cognition_related': True,\n",
       "  'condition': 'Dementia',\n",
       "  'care_hours': '24',\n",
       "  'source': 'decision_10.txt'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let read all the lines and put into a list\n",
    "\n",
    "## let's see what the first line of file contains\n",
    "decisions_list = []\n",
    "for myfile in myfiles:\n",
    "#     ic(myfile)\n",
    "    with open(myfile, \"r\") as textfile:\n",
    "        all_lines = textfile.readlines()\n",
    "#         ic(all_lines)\n",
    "        source = myfile\n",
    "        year = all_lines[0].replace(\"Year: \", \"\").replace(\"\\n\", \"\")\n",
    "#         print(year)\n",
    "        condition = all_lines[2]\n",
    "#         print(f\"The sentence reads {condition}\")\n",
    "        if \"determined to suffer from Dementia\" in condition:\n",
    "            condition = \"Dementia\"\n",
    "            cog_related = True\n",
    "        elif \"determined to suffer from Alzheimer's\" in condition:\n",
    "            condition = \"Alzheimer's\"\n",
    "            cog_related = True\n",
    "             \n",
    "        else: \n",
    "            condition = \"A/D not indicated \"\n",
    "            cog_related = False\n",
    "            \n",
    "        care_hours = all_lines[-1]\n",
    "#         ic(care_hours)\n",
    "        if \"24-hour\" in care_hours:\n",
    "            care_hours = \"24\"\n",
    "            \n",
    "        elif \"12-hour\" in care_hours:\n",
    "            care_hours = \"12\"\n",
    "        else:\n",
    "            care_hours = \"not specified\"\n",
    "#     ic(source)        \n",
    "#     ic(condition)\n",
    "#     ic(cog_related)\n",
    "#         ic(care_hours)\n",
    "        care_dict = {\"year\": year, \"cognition_related\": cog_related,\n",
    "                    \"condition\": condition, \"care_hours\": care_hours,\n",
    "                    \"source\": myfile}\n",
    "        decisions_list.append(care_dict)\n",
    "    \n",
    "\n",
    "decisions_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>cognition_related</th>\n",
       "      <th>condition</th>\n",
       "      <th>care_hours</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>24</td>\n",
       "      <td>decision_01.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>False</td>\n",
       "      <td>A/D not indicated</td>\n",
       "      <td>not specified</td>\n",
       "      <td>decision_02.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Alzheimer's</td>\n",
       "      <td>24</td>\n",
       "      <td>decision_03.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>12</td>\n",
       "      <td>decision_04.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>12</td>\n",
       "      <td>decision_05.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>12</td>\n",
       "      <td>decision_06.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>False</td>\n",
       "      <td>A/D not indicated</td>\n",
       "      <td>not specified</td>\n",
       "      <td>decision_07.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>24</td>\n",
       "      <td>decision_08.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>24</td>\n",
       "      <td>decision_09.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>True</td>\n",
       "      <td>Dementia</td>\n",
       "      <td>24</td>\n",
       "      <td>decision_10.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  cognition_related           condition     care_hours           source\n",
       "0  2018               True            Dementia             24  decision_01.txt\n",
       "1  2018              False  A/D not indicated   not specified  decision_02.txt\n",
       "2  2018               True         Alzheimer's             24  decision_03.txt\n",
       "3  2018               True            Dementia             12  decision_04.txt\n",
       "4  2018               True            Dementia             12  decision_05.txt\n",
       "5  2018               True            Dementia             12  decision_06.txt\n",
       "6  2018              False  A/D not indicated   not specified  decision_07.txt\n",
       "7  2018               True            Dementia             24  decision_08.txt\n",
       "8  2018               True            Dementia             24  decision_09.txt\n",
       "9  2018               True            Dementia             24  decision_10.txt"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(decisions_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y72rctb5D-Gu"
   },
   "outputs": [],
   "source": [
    "## Now let's place clients and decisions into variables called client and decision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yuvCxJoD-KT"
   },
   "outputs": [],
   "source": [
    "## let's remove the word client and the extra line\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opp5s8STjCye"
   },
   "outputs": [],
   "source": [
    "## We don't want an entire sentence â€“ just what the decision was.\n",
    "## we just want to know the status of lease in one word renew or terminate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9hEhNKkXjYHT"
   },
   "outputs": [],
   "source": [
    "## We want to store in a list to export as CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isxnLpPRlCRa"
   },
   "source": [
    "### Confirm where we are path-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-Qc3BZ8lCRa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9KTw-enlCRb"
   },
   "source": [
    "### Create new results directory (note we come out of the downloaded_files folder first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WglOFfLHlCRb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otpHcPn4lCRb"
   },
   "outputs": [],
   "source": [
    "### cd into our results folder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKYRUg24lCRb"
   },
   "source": [
    "### Confirm we are in the results folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-AMX1rIlCRb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIw6MAQNkazG"
   },
   "outputs": [],
   "source": [
    "## Export as CSV\n",
    "\n",
    "## use pandas to write to csv file\n",
    "## we already imported pandas as pd\n",
    "filename = \"lease_decisions.csv\" ## what are file name is\n",
    "df = pd.DataFrame(decisions) ## we turn our list of dicts into a dataframe which we're call df\n",
    "df\n",
    "df.to_csv(filename, encoding='utf-8', index=False) ## export to csv as utf-8 coding (it just has to be this)\n",
    "print(f\"{filename} is in your results folder!\") ## a print out that tells us the file is ready"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "name": "week-8C-download-and-read_BLANK.ipynb",
   "provenance": [
    {
     "file_id": "1tC30RwvbvYZQU9bLZ75I6kBbMski9LFN",
     "timestamp": 1628626954402
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
